{
  
    
        "post0": {
            "title": "Coronavirus COVID-19 Tweets",
            "content": "!pip install padelpy . Collecting padelpy Downloading padelpy-0.1.11-py2.py3-none-any.whl (20.9 MB) |████████████████████████████████| 20.9 MB 1.3 MB/s Installing collected packages: padelpy Successfully installed padelpy-0.1.11 . Data preparation . Load packages . import numpy as np import pandas as pd import matplotlib import seaborn as sns import matplotlib.pyplot as plt %matplotlib inline from wordcloud import WordCloud, STOPWORDS . Load data . tweets_df = pd.read_csv(&quot;covid19_tweets.csv&quot;) . Data exploration . Glimpse the data . print(f&quot;data shape: {tweets_df.shape}&quot;) . tweets_df.info() . tweets_df.describe() . tweets_df.head() . Missing data . def missing_data(data): total = data.isnull().sum() percent = (data.isnull().sum()/data.isnull().count()*100) tt = pd.concat([total, percent], axis=1, keys=[&#39;Total&#39;, &#39;Percent&#39;]) types = [] for col in data.columns: dtype = str(data[col].dtype) types.append(dtype) tt[&#39;Types&#39;] = types return(np.transpose(tt)) . missing_data(tweets_df) . Unique values . def unique_values(data): total = data.count() tt = pd.DataFrame(total) tt.columns = [&#39;Total&#39;] uniques = [] for col in data.columns: unique = data[col].nunique() uniques.append(unique) tt[&#39;Uniques&#39;] = uniques return(np.transpose(tt)) . unique_values(tweets_df) . Most frequent values . def most_frequent_values(data): total = data.count() tt = pd.DataFrame(total) tt.columns = [&#39;Total&#39;] items = [] vals = [] for col in data.columns: itm = data[col].value_counts().index[0] val = data[col].value_counts().values[0] items.append(itm) vals.append(val) tt[&#39;Most frequent item&#39;] = items tt[&#39;Frequence&#39;] = vals tt[&#39;Percent from total&#39;] = np.round(vals / total * 100, 3) return(np.transpose(tt)) . most_frequent_values(tweets_df) . Visualize the data distribution . def plot_count(feature, title, df, size=1, ordered=True): f, ax = plt.subplots(1,1, figsize=(4*size,4)) total = float(len(df)) if ordered: g = sns.countplot(df[feature], order = df[feature].value_counts().index[:20], palette=&#39;Set3&#39;) else: g = sns.countplot(df[feature], palette=&#39;Set3&#39;) g.set_title(&quot;Number and percentage of {}&quot;.format(title)) if(size &gt; 2): plt.xticks(rotation=90, size=8) for p in ax.patches: height = p.get_height() ax.text(p.get_x()+p.get_width()/2., height + 3, &#39;{:1.2f}%&#39;.format(100*height/total), ha=&quot;center&quot;) plt.show() . User name . plot_count(&quot;user_name&quot;, &quot;User name&quot;, tweets_df,4) . User location . plot_count(&quot;user_location&quot;, &quot;User location&quot;, tweets_df,4) . Tweet source . plot_count(&quot;source&quot;, &quot;Source&quot;, tweets_df,4) . stopwords = set(STOPWORDS) def show_wordcloud(data, title = None): wordcloud = WordCloud( background_color=&#39;white&#39;, stopwords=stopwords, max_words=50, max_font_size=40, scale=5, random_state=1 ).generate(str(data)) fig = plt.figure(1, figsize=(10,10)) plt.axis(&#39;off&#39;) if title: fig.suptitle(title, fontsize=20) fig.subplots_adjust(top=2.3) plt.imshow(wordcloud) plt.show() . Text wordcloauds . show_wordcloud(tweets_df[&#39;text&#39;], title = &#39;Prevalent words in tweets&#39;) . india_df = tweets_df.loc[tweets_df.user_location==&quot;India&quot;] show_wordcloud(india_df[&#39;text&#39;], title = &#39;Prevalent words in tweets from India&#39;) . us_df = tweets_df.loc[tweets_df.user_location==&quot;United States&quot;] show_wordcloud(us_df[&#39;text&#39;], title = &#39;Prevalent words in tweets from US&#39;) . us_df = tweets_df.loc[tweets_df.user_location==&quot;United Kingdom&quot;] show_wordcloud(us_df[&#39;text&#39;], title = &#39;Prevalent words in tweets from UK&#39;) . us_df = tweets_df.loc[tweets_df.user_location==&quot;Canada&quot;] show_wordcloud(us_df[&#39;text&#39;], title = &#39;Prevalent words in tweets from Canada&#39;) . india_df = tweets_df.loc[tweets_df.user_location==&quot;South Africa&quot;] show_wordcloud(india_df[&#39;text&#39;], title = &#39;Prevalent words in tweets from South Africa&#39;) . india_df = tweets_df.loc[tweets_df.user_location==&quot;Switzerland&quot;] show_wordcloud(india_df[&#39;text&#39;], title = &#39;Prevalent words in tweets from Switzerland&#39;) . us_df = tweets_df.loc[tweets_df.user_location==&quot;London&quot;] show_wordcloud(us_df[&#39;text&#39;], title = &#39;Prevalent words in tweets from London&#39;) . Hashtags analysis . def plot_features_distribution(features, title, df, isLog=False): plt.figure(figsize=(12,6)) plt.title(title) for feature in features: if(isLog): sns.distplot(np.log1p(df[feature]),kde=True,hist=False, bins=120, label=feature) else: sns.distplot(df[feature],kde=True,hist=False, bins=120, label=feature) plt.xlabel(&#39;&#39;) plt.legend() plt.show() . tweets_df[&#39;hashtags&#39;] = tweets_df[&#39;hashtags&#39;].replace(np.nan, &quot;[&#39;None&#39;]&quot;, regex=True) tweets_df[&#39;hashtags&#39;] = tweets_df[&#39;hashtags&#39;].apply(lambda x: x.replace(&#39; N&#39;,&#39;&#39;)) tweets_df[&#39;hashtags_count&#39;] = tweets_df[&#39;hashtags&#39;].apply(lambda x: len(x.split(&#39;,&#39;))) plot_features_distribution([&#39;hashtags_count&#39;], &#39;Hashtags per tweet (all data)&#39;, tweets_df) . tweets_df[&#39;hashtags_individual&#39;] = tweets_df[&#39;hashtags&#39;].apply(lambda x: x.split(&#39;,&#39;)) from itertools import chain all_hashtags = set(chain.from_iterable(list(tweets_df[&#39;hashtags_individual&#39;]))) print(f&quot;There are totally: {len(all_hashtags)}&quot;) . show_wordcloud(tweets_df[&#39;hashtags_individual&#39;], title = &#39;Prevalent words in hashtags&#39;) . Extract country from location . We load the country list from the additional database we added to this Notebook. We also create a country column in the original dataset. . country_df = pd.read_csv(&quot;../input/iso-country-codes-global/wikipedia-iso-country-codes.csv&quot;) . FileNotFoundError Traceback (most recent call last) &lt;ipython-input-30-e8e1dff238c3&gt; in &lt;module&gt;() -&gt; 1 country_df = pd.read_csv(&#34;../input/iso-country-codes-global/wikipedia-iso-country-codes.csv&#34;) /usr/local/lib/python3.7/dist-packages/pandas/util/_decorators.py in wrapper(*args, **kwargs) 309 stacklevel=stacklevel, 310 ) --&gt; 311 return func(*args, **kwargs) 312 313 return wrapper /usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py in read_csv(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options) 584 kwds.update(kwds_defaults) 585 --&gt; 586 return _read(filepath_or_buffer, kwds) 587 588 /usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py in _read(filepath_or_buffer, kwds) 480 481 # Create the parser. --&gt; 482 parser = TextFileReader(filepath_or_buffer, **kwds) 483 484 if chunksize or iterator: /usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py in __init__(self, f, engine, **kwds) 809 self.options[&#34;has_index_names&#34;] = kwds[&#34;has_index_names&#34;] 810 --&gt; 811 self._engine = self._make_engine(self.engine) 812 813 def close(self): /usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py in _make_engine(self, engine) 1038 ) 1039 # error: Too many arguments for &#34;ParserBase&#34; -&gt; 1040 return mapping[engine](self.f, **self.options) # type: ignore[call-arg] 1041 1042 def _failover_to_python(self): /usr/local/lib/python3.7/dist-packages/pandas/io/parsers/c_parser_wrapper.py in __init__(self, src, **kwds) 49 50 # open handles &gt; 51 self._open_handles(src, kwds) 52 assert self.handles is not None 53 /usr/local/lib/python3.7/dist-packages/pandas/io/parsers/base_parser.py in _open_handles(self, src, kwds) 227 memory_map=kwds.get(&#34;memory_map&#34;, False), 228 storage_options=kwds.get(&#34;storage_options&#34;, None), --&gt; 229 errors=kwds.get(&#34;encoding_errors&#34;, &#34;strict&#34;), 230 ) 231 /usr/local/lib/python3.7/dist-packages/pandas/io/common.py in get_handle(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options) 705 encoding=ioargs.encoding, 706 errors=errors, --&gt; 707 newline=&#34;&#34;, 708 ) 709 else: FileNotFoundError: [Errno 2] No such file or directory: &#39;../input/iso-country-codes-global/wikipedia-iso-country-codes.csv&#39; . country_df.columns = [&quot;country&quot;, &quot;alpha2&quot;, &quot;alpha3&quot;, &quot;numeric&quot;, &quot;iso&quot;] country_df.head() . tweets_df[&#39;country&#39;] = tweets_df[&#39;user_location&#39;] . We merge the countries dataset with the tweets dataset. . tweets_df = tweets_df.merge(country_df, on=&quot;country&quot;) . tweets_df.head(10) . tw_add_df = tweets_df.groupby([&quot;country&quot;, &quot;iso&quot;, &quot;alpha3&quot;])[&#39;text&#39;].count().reset_index() tw_add_df.columns = [&quot;country&quot;, &quot;iso&quot;, &quot;alpha3&quot;, &quot;tweets&quot;] . import plotly.express as px def plot_map(dd_df, title): hover_text = [] for index, row in dd_df.iterrows(): hover_text.append((f&quot;country: {row[&#39;country&#39;]}&lt;br&gt;tweets: {row[&#39;tweets&#39;]} &lt;br&gt;country code: {row[&#39;iso&#39;]}&lt;br&gt;country alpha3: {row[&#39;alpha3&#39;]}&quot;)) dd_df[&#39;hover_text&#39;] = hover_text fig = px.choropleth(dd_df, locations=&quot;alpha3&quot;, hover_name=&#39;hover_text&#39;, color=&quot;tweets&quot;, projection=&quot;natural earth&quot;, color_continuous_scale=px.colors.sequential.Plasma, width=900, height=700) fig.update_geos( showcoastlines=True, coastlinecolor=&quot;DarkBlue&quot;, showland=True, landcolor=&quot;LightGrey&quot;, showocean=True, oceancolor=&quot;LightBlue&quot;, showlakes=True, lakecolor=&quot;Blue&quot;, showrivers=True, rivercolor=&quot;Blue&quot;, showcountries=True, countrycolor=&quot;DarkBlue&quot; ) fig.update_layout(title = title, geo_scope=&quot;world&quot;) fig.show() . plot_map(tw_add_df, &quot;Tweets per country (where country is specified)&quot;) . Extract date and time features . tweets_df[&#39;datedt&#39;] = pd.to_datetime(tweets_df[&#39;date&#39;]) . tweets_df[&#39;year&#39;] = tweets_df[&#39;datedt&#39;].dt.year tweets_df[&#39;month&#39;] = tweets_df[&#39;datedt&#39;].dt.month tweets_df[&#39;day&#39;] = tweets_df[&#39;datedt&#39;].dt.day tweets_df[&#39;dayofweek&#39;] = tweets_df[&#39;datedt&#39;].dt.dayofweek tweets_df[&#39;hour&#39;] = tweets_df[&#39;datedt&#39;].dt.hour tweets_df[&#39;minute&#39;] = tweets_df[&#39;datedt&#39;].dt.minute tweets_df[&#39;dayofyear&#39;] = tweets_df[&#39;datedt&#39;].dt.dayofyear tweets_df[&#39;date_only&#39;] = tweets_df[&#39;datedt&#39;].dt.date . Time variation . tweets_agg_df = tweets_df.groupby([&quot;date_only&quot;])[&quot;text&quot;].count().reset_index() tweets_agg_df.columns = [&quot;date_only&quot;, &quot;count&quot;] . def plot_time_variation(df, x=&#39;date_only&#39;, y=&#39;count&#39;, hue=None, size=1, title=&quot;&quot;, is_log=False): f, ax = plt.subplots(1,1, figsize=(4*size,3*size)) g = sns.lineplot(x=x, y=y, hue=hue, data=df) plt.xticks(rotation=90) if hue: plt.title(f&#39;{y} grouped by {hue} | {title}&#39;) else: plt.title(f&#39;{y} | {title}&#39;) if(is_log): ax.set(yscale=&quot;log&quot;) ax.grid(color=&#39;black&#39;, linestyle=&#39;dotted&#39;, linewidth=0.75) plt.show() . plot_time_variation(tweets_agg_df, title=&quot;Number of tweets / day of year&quot;,size=3) . plot_count(&quot;dayofweek&quot;, &quot;tweets / day of week&quot;, tweets_df, size=3, ordered=False) . plot_count(&quot;dayofyear&quot;, &quot;tweets / day of year&quot;, tweets_df, size=3, ordered=False) . plot_count(&quot;date_only&quot;, &quot;tweets / date&quot;, tweets_df,size=4, ordered=False) . plot_count(&quot;hour&quot;, &quot;tweets / hour&quot;, tweets_df,size=4, ordered=False) . plot_count(&quot;minute&quot;, &quot;tweets / minute&quot;, tweets_df,size=5, ordered=False) .",
            "url": "https://princeexpert17.github.io/bettertech/padelpy/corona-virus/scikit-learn/2022/03/18/covid19.html",
            "relUrl": "/padelpy/corona-virus/scikit-learn/2022/03/18/covid19.html",
            "date": " • Mar 18, 2022"
        }
        
    
  
    
        ,"post1": {
            "title": "Fastpages Notebook Blog Post",
            "content": "About . This notebook is a demonstration of some of capabilities of fastpages with notebooks. . With fastpages you can save your jupyter notebooks into the _notebooks folder at the root of your repository, and they will be automatically be converted to Jekyll compliant blog posts! . Front Matter . The first cell in your Jupyter Notebook or markdown blog post contains front matter. Front matter is metadata that can turn on/off options in your Notebook. It is formatted like this: . # &quot;My Title&quot; &gt; &quot;Awesome summary&quot; - toc:true- branch: master - badges: true - comments: true - author: Hamel Husain &amp; Jeremy Howard - categories: [fastpages, jupyter] . Setting toc: true will automatically generate a table of contents | Setting badges: true will automatically include GitHub and Google Colab links to your notebook. | Setting comments: true will enable commenting on your blog post, powered by utterances. | . The title and description need to be enclosed in double quotes only if they include special characters such as a colon. More details and options for front matter can be viewed on the front matter section of the README. . Markdown Shortcuts . A #hide comment at the top of any code cell will hide both the input and output of that cell in your blog post. . A #hide_input comment at the top of any code cell will only hide the input of that cell. . The comment #hide_input was used to hide the code that produced this. . put a #collapse-hide flag at the top of any cell if you want to hide that cell by default, but give the reader the option to show it: . import pandas as pd import altair as alt . . put a #collapse-show flag at the top of any cell if you want to show that cell by default, but give the reader the option to hide it: . cars = &#39;https://vega.github.io/vega-datasets/data/cars.json&#39; movies = &#39;https://vega.github.io/vega-datasets/data/movies.json&#39; sp500 = &#39;https://vega.github.io/vega-datasets/data/sp500.csv&#39; stocks = &#39;https://vega.github.io/vega-datasets/data/stocks.csv&#39; flights = &#39;https://vega.github.io/vega-datasets/data/flights-5k.json&#39; . . place a #collapse-output flag at the top of any cell if you want to put the output under a collapsable element that is closed by default, but give the reader the option to open it: . print(&#39;The comment #collapse-output was used to collapse the output of this cell by default but you can expand it.&#39;) . The comment #collapse-output was used to collapse the output of this cell by default but you can expand it. . . Interactive Charts With Altair . Charts made with Altair remain interactive. Example charts taken from this repo, specifically this notebook. . Example 1: DropDown . # use specific hard-wired values as the initial selected values selection = alt.selection_single( name=&#39;Select&#39;, fields=[&#39;Major_Genre&#39;, &#39;MPAA_Rating&#39;], init={&#39;Major_Genre&#39;: &#39;Drama&#39;, &#39;MPAA_Rating&#39;: &#39;R&#39;}, bind={&#39;Major_Genre&#39;: alt.binding_select(options=genres), &#39;MPAA_Rating&#39;: alt.binding_radio(options=mpaa)} ) # scatter plot, modify opacity based on selection alt.Chart(df).mark_circle().add_selection( selection ).encode( x=&#39;Rotten_Tomatoes_Rating:Q&#39;, y=&#39;IMDB_Rating:Q&#39;, tooltip=&#39;Title:N&#39;, opacity=alt.condition(selection, alt.value(0.75), alt.value(0.05)) ) . Example 2: Tooltips . alt.Chart(df).mark_circle().add_selection( alt.selection_interval(bind=&#39;scales&#39;, encodings=[&#39;x&#39;]) ).encode( alt.X(&#39;Rotten_Tomatoes_Rating&#39;, type=&#39;quantitative&#39;), alt.Y(&#39;IMDB_Rating&#39;, type=&#39;quantitative&#39;, axis=alt.Axis(minExtent=30)), # y=alt.Y(&#39;IMDB_Rating:Q&#39;, ), # use min extent to stabilize axis title placement tooltip=[&#39;Title:N&#39;, &#39;Release_Date:N&#39;, &#39;IMDB_Rating:Q&#39;, &#39;Rotten_Tomatoes_Rating:Q&#39;] ).properties( width=500, height=400 ) . Example 3: More Tooltips . label = alt.selection_single( encodings=[&#39;x&#39;], # limit selection to x-axis value on=&#39;mouseover&#39;, # select on mouseover events nearest=True, # select data point nearest the cursor empty=&#39;none&#39; # empty selection includes no data points ) # define our base line chart of stock prices base = alt.Chart().mark_line().encode( alt.X(&#39;date:T&#39;), alt.Y(&#39;price:Q&#39;, scale=alt.Scale(type=&#39;log&#39;)), alt.Color(&#39;symbol:N&#39;) ) alt.layer( base, # base line chart # add a rule mark to serve as a guide line alt.Chart().mark_rule(color=&#39;#aaa&#39;).encode( x=&#39;date:T&#39; ).transform_filter(label), # add circle marks for selected time points, hide unselected points base.mark_circle().encode( opacity=alt.condition(label, alt.value(1), alt.value(0)) ).add_selection(label), # add white stroked text to provide a legible background for labels base.mark_text(align=&#39;left&#39;, dx=5, dy=-5, stroke=&#39;white&#39;, strokeWidth=2).encode( text=&#39;price:Q&#39; ).transform_filter(label), # add text labels for stock prices base.mark_text(align=&#39;left&#39;, dx=5, dy=-5).encode( text=&#39;price:Q&#39; ).transform_filter(label), data=stocks ).properties( width=500, height=400 ) . Data Tables . You can display tables per the usual way in your blog: . df[[&#39;Title&#39;, &#39;Worldwide_Gross&#39;, &#39;Production_Budget&#39;, &#39;Distributor&#39;, &#39;MPAA_Rating&#39;, &#39;IMDB_Rating&#39;, &#39;Rotten_Tomatoes_Rating&#39;]].head() . Title Worldwide_Gross Production_Budget Distributor MPAA_Rating IMDB_Rating Rotten_Tomatoes_Rating . 0 The Land Girls | 146083.0 | 8000000.0 | Gramercy | R | 6.1 | NaN | . 1 First Love, Last Rites | 10876.0 | 300000.0 | Strand | R | 6.9 | NaN | . 2 I Married a Strange Person | 203134.0 | 250000.0 | Lionsgate | None | 6.8 | NaN | . 3 Let&#39;s Talk About Sex | 373615.0 | 300000.0 | Fine Line | None | NaN | 13.0 | . 4 Slam | 1087521.0 | 1000000.0 | Trimark | R | 3.4 | 62.0 | . Images . Local Images . You can reference local images and they will be copied and rendered on your blog automatically. You can include these with the following markdown syntax: . ![](my_icons/fastai_logo.png) . . Remote Images . Remote images can be included with the following markdown syntax: . ![](https://image.flaticon.com/icons/svg/36/36686.svg) . . Animated Gifs . Animated Gifs work, too! . ![](https://upload.wikimedia.org/wikipedia/commons/7/71/ChessPawnSpecialMoves.gif) . . Captions . You can include captions with markdown images like this: . ![](https://www.fast.ai/images/fastai_paper/show_batch.png &quot;Credit: https://www.fast.ai/2020/02/13/fastai-A-Layered-API-for-Deep-Learning/&quot;) . . Other Elements . GitHub Flavored Emojis . Typing I give this post two :+1:! will render this: . I give this post two :+1:! . Tweetcards . Typing &gt; twitter: https://twitter.com/jakevdp/status/1204765621767901185?s=20 will render this: Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 . Youtube Videos . Typing &gt; youtube: https://youtu.be/XfoYk_Z5AkI will render this: . Boxes / Callouts . Typing &gt; Warning: There will be no second warning! will render this: . Warning: There will be no second warning! . Typing &gt; Important: Pay attention! It&#39;s important. will render this: . Important: Pay attention! It&#8217;s important. . Typing &gt; Tip: This is my tip. will render this: . Tip: This is my tip. . Typing &gt; Note: Take note of this. will render this: . Note: Take note of this. . Typing &gt; Note: A doc link to [an example website: fast.ai](https://www.fast.ai/) should also work fine. will render in the docs: . Note: A doc link to an example website: fast.ai should also work fine. . Footnotes . You can have footnotes in notebooks, however the syntax is different compared to markdown documents. This guide provides more detail about this syntax, which looks like this: . For example, here is a footnote {% fn 1 %}. And another {% fn 2 %} {{ &#39;This is the footnote.&#39; | fndetail: 1 }} {{ &#39;This is the other footnote. You can even have a [link](www.github.com)!&#39; | fndetail: 2 }} . For example, here is a footnote 1. . And another 2 . 1. This is the footnote.↩ . 2. This is the other footnote. You can even have a link!↩ .",
            "url": "https://princeexpert17.github.io/bettertech/jupyter/2020/02/20/test.html",
            "relUrl": "/jupyter/2020/02/20/test.html",
            "date": " • Feb 20, 2020"
        }
        
    
  
    
        ,"post2": {
            "title": "An Example Markdown Post",
            "content": "Example Markdown Post . Basic setup . Jekyll requires blog post files to be named according to the following format: . YEAR-MONTH-DAY-filename.md . Where YEAR is a four-digit number, MONTH and DAY are both two-digit numbers, and filename is whatever file name you choose, to remind yourself what this post is about. .md is the file extension for markdown files. . The first line of the file should start with a single hash character, then a space, then your title. This is how you create a “level 1 heading” in markdown. Then you can create level 2, 3, etc headings as you wish but repeating the hash character, such as you see in the line ## File names above. . Basic formatting . You can use italics, bold, code font text, and create links. Here’s a footnote 1. Here’s a horizontal rule: . . Lists . Here’s a list: . item 1 | item 2 | . And a numbered list: . item 1 | item 2 | Boxes and stuff . This is a quotation . . You can include alert boxes …and… . . You can include info boxes Images . . Code . You can format text and code per usual . General preformatted text: . # Do a thing do_thing() . Python code and output: . # Prints &#39;2&#39; print(1+1) . 2 . Formatting text as shell commands: . echo &quot;hello world&quot; ./some_script.sh --option &quot;value&quot; wget https://example.com/cat_photo1.png . Formatting text as YAML: . key: value - another_key: &quot;another value&quot; . Tables . Column 1 Column 2 . A thing | Another thing | . Tweetcards . Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 Footnotes . This is the footnote. &#8617; . |",
            "url": "https://princeexpert17.github.io/bettertech/markdown/2020/01/14/test-markdown-post.html",
            "relUrl": "/markdown/2020/01/14/test-markdown-post.html",
            "date": " • Jan 14, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "This website is powered by fastpages 1. . a blogging platform that natively supports Jupyter notebooks in addition to other formats. &#8617; . |",
          "url": "https://princeexpert17.github.io/bettertech/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://princeexpert17.github.io/bettertech/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}